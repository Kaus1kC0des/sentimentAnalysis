{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:25:06.484880600Z",
     "start_time": "2023-09-17T13:23:54.254514500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 2)) (1.24.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 3)) (0.12.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 4)) (3.8.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 5)) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: scikit-learn-intelex in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 7)) (2023.2.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 8)) (4.33.2)\n",
      "Collecting text_hammer (from -r requirements.txt (line 9))\n",
      "  Using cached text_hammer-0.1.5-py3-none-any.whl (7.6 kB)\n",
      "Collecting spacy (from -r requirements.txt (line 10))\n",
      "  Obtaining dependency information for spacy from https://files.pythonhosted.org/packages/d6/9e/8afc618cfed4b5dc602b11754d4d9193a268439704defae301bffca7f04c/spacy-3.6.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached spacy-3.6.1-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting tensorflow (from -r requirements.txt (line 11))\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/9e/b8/ed5f794359d05cd0bffb894c6418da87b93016ee17b669d55c45d1bd5d5b/tensorflow-2.13.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached tensorflow-2.13.0-cp311-cp311-win_amd64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: opendatasets in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 12)) (0.1.22)\n",
      "Collecting datasets (from -r requirements.txt (line 13))\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/09/7e/fd4d6441a541dba61d0acb3c1fd5df53214c2e9033854e837a99dd9e0793/datasets-2.14.5-py3-none-any.whl.metadata\n",
      "  Using cached datasets-2.14.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 14)) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (3.1.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 6)) (3.2.0)\n",
      "Requirement already satisfied: daal4py==2023.2.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from scikit-learn-intelex->-r requirements.txt (line 7)) (2023.2.1)\n",
      "Requirement already satisfied: daal==2023.2.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from daal4py==2023.2.1->scikit-learn-intelex->-r requirements.txt (line 7)) (2023.2.1)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from daal==2023.2.1->daal4py==2023.2.1->scikit-learn-intelex->-r requirements.txt (line 7)) (2021.10.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (0.17.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (2023.8.8)\n",
      "Requirement already satisfied: requests in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (4.66.1)\n",
      "Requirement already satisfied: beautifulsoup4==4.9.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from text_hammer->-r requirements.txt (line 9)) (4.9.1)\n",
      "Requirement already satisfied: TextBlob in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from text_hammer->-r requirements.txt (line 9)) (0.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from beautifulsoup4==4.9.1->text_hammer->-r requirements.txt (line 9)) (2.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (6.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (68.0.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (3.3.0)\n",
      "Collecting tensorflow-intel==2.13.0 (from tensorflow->-r requirements.txt (line 11))\n",
      "  Obtaining dependency information for tensorflow-intel==2.13.0 from https://files.pythonhosted.org/packages/2f/2f/3c84f675931ce3bcbc7e23acbba1e5d7f05ce769adab48322de57a9f5928/tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (4.24.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (1.58.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (0.31.0)\n",
      "Requirement already satisfied: kaggle in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from opendatasets->-r requirements.txt (line 12)) (1.5.16)\n",
      "Requirement already satisfied: click in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from opendatasets->-r requirements.txt (line 12)) (8.1.7)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from datasets->-r requirements.txt (line 13)) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from datasets->-r requirements.txt (line 13)) (0.3.7)\n",
      "Requirement already satisfied: xxhash in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from datasets->-r requirements.txt (line 13)) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from datasets->-r requirements.txt (line 13)) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from datasets->-r requirements.txt (line 13)) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from datasets->-r requirements.txt (line 13)) (3.8.5)\n",
      "Requirement already satisfied: sympy in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from torch->-r requirements.txt (line 14)) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from torch->-r requirements.txt (line 14)) (3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 8)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 8)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 8)) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy->-r requirements.txt (line 10)) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy->-r requirements.txt (line 10)) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tqdm>=4.27->transformers->-r requirements.txt (line 8)) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from jinja2->spacy->-r requirements.txt (line 10)) (2.1.1)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from kaggle->opendatasets->-r requirements.txt (line 12)) (8.0.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from kaggle->opendatasets->-r requirements.txt (line 12)) (4.1.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from sympy->torch->-r requirements.txt (line 14)) (1.3.0)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from TextBlob->text_hammer->-r requirements.txt (line 9)) (3.8.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (3.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (2.3.7)\n",
      "Requirement already satisfied: webencodings in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from bleach->kaggle->opendatasets->-r requirements.txt (line 12)) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from python-slugify->kaggle->opendatasets->-r requirements.txt (line 12)) (1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (3.2.2)\n",
      "Using cached spacy-3.6.1-cp311-cp311-win_amd64.whl (12.0 MB)\n",
      "Using cached tensorflow-2.13.0-cp311-cp311-win_amd64.whl (1.9 kB)\n",
      "Using cached tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl (276.6 MB)\n",
      "Using cached datasets-2.14.5-py3-none-any.whl (519 kB)\n",
      "Installing collected packages: spacy, datasets, text_hammer, tensorflow-intel, tensorflow\n",
      "Successfully installed datasets-2.14.5 spacy-3.6.1 tensorflow-2.13.0 tensorflow-intel-2.13.0 text_hammer-0.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:Your Kaggle Key:Downloading sentiment140.zip to .\\sentiment140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80.9M/80.9M [00:04<00:00, 18.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/kazanova/sentiment140\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T19:25:30.055927300Z",
     "start_time": "2023-09-17T19:24:55.274248900Z"
    }
   },
   "id": "24baa191e81bc95e"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "   sentiment          id                          date     query  \\\n0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n\n              user                                               text  \n0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n1    scotthamilton  is upset that he can't update his Facebook by ...  \n2         mattycus  @Kenichan I dived many times for the ball. Man...  \n3          ElleCTF    my whole body feels itchy and like its on fire   \n4           Karoli  @nationwideclass no, it's not behaving at all....  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>id</th>\n      <th>date</th>\n      <th>query</th>\n      <th>user</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\kausikdevanathan\\DataspellProjects\\sentimentAnalysis\\sentiment140\\training.1600000.processed.noemoticon.csv\",names=[\"sentiment\",\"id\",\"date\",\"query\",\"user\",\"text\"],encoding='latin-1')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T07:31:09.876568900Z",
     "start_time": "2023-09-18T07:31:04.607220500Z"
    }
   },
   "id": "932b49979d9817b1"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "sentiment    0\nid           0\ndate         0\nquery        0\nuser         0\ntext         0\ndtype: int64"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:26:31.379365200Z",
     "start_time": "2023-09-18T05:26:31.007824500Z"
    }
   },
   "id": "ffa7ff97050dc84c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df.drop([\"id\",\"date\",\"query\",\"user\"],axis=1,inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:26:31.381805Z",
     "start_time": "2023-09-18T05:26:31.272925600Z"
    }
   },
   "id": "6ab08b23077f4974"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   sentiment                                               text\n0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n1          0  is upset that he can't update his Facebook by ...\n2          0  @Kenichan I dived many times for the ball. Man...\n3          0    my whole body feels itchy and like its on fire \n4          0  @nationwideclass no, it's not behaving at all....",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:26:31.383952200Z",
     "start_time": "2023-09-18T05:26:31.317365800Z"
    }
   },
   "id": "d6f036ab942a77a4"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.pipelines because of the following error (look up to see its traceback):\ncannot import name 'ARRAY_FUNCTIONS' from 'numpy.core.overrides' (C:\\Users\\kausikdevanathan\\anaconda3\\envs\\SIH\\Lib\\site-packages\\numpy\\core\\overrides.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1184\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[1;34m(self, module_name)\u001B[0m\n\u001B[0;32m   1183\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1184\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m module_name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m   1185\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\importlib\\__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _bootstrap\u001B[38;5;241m.\u001B[39m_gcd_import(name[level:], package, level)\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1204\u001B[0m, in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1176\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1147\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:690\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:940\u001B[0m, in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:241\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[1;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:62\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdepth_estimation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DepthEstimationPipeline\n\u001B[1;32m---> 62\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdocument_question_answering\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DocumentQuestionAnsweringPipeline\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeature_extraction\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FeatureExtractionPipeline\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\transformers\\pipelines\\document_question_answering.py:29\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PIPELINE_INIT_ARGS, ChunkPipeline\n\u001B[1;32m---> 29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mquestion_answering\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m select_starts_ends\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_vision_available():\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\transformers\\pipelines\\question_answering.py:9\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SquadExample, SquadFeatures, squad_convert_examples_to_features\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodelcard\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ModelCard\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\transformers\\data\\__init__.py:26\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_collator\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     16\u001B[0m     DataCollatorForLanguageModeling,\n\u001B[0;32m     17\u001B[0m     DataCollatorForPermutationLanguageModeling,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     24\u001B[0m     default_data_collator,\n\u001B[0;32m     25\u001B[0m )\n\u001B[1;32m---> 26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m glue_compute_metrics, xnli_compute_metrics\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprocessors\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     28\u001B[0m     DataProcessor,\n\u001B[0;32m     29\u001B[0m     InputExample,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     43\u001B[0m     xnli_tasks_num_labels,\n\u001B[0;32m     44\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\transformers\\data\\metrics\\__init__.py:19\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_sklearn_available():\n\u001B[1;32m---> 19\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstats\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pearsonr, spearmanr\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m f1_score, matthews_corrcoef\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\scipy\\stats\\__init__.py:608\u001B[0m\n\u001B[0;32m    606\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_warnings_errors\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001B[0;32m    607\u001B[0m                                DegenerateDataWarning, FitError)\n\u001B[1;32m--> 608\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_stats_py\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m    609\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_variation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m variation\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:37\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NumpyVersion\n\u001B[1;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtesting\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m suppress_warnings\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mspatial\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistance\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cdist\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\numpy\\testing\\__init__.py:14\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_private\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m extbuild\n\u001B[1;32m---> 14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m overrides\n\u001B[0;32m     16\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     17\u001B[0m     _private\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39m__all__ \u001B[38;5;241m+\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTestCase\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moverrides\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     18\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\numpy\\testing\\overrides.py:6\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"Tools for testing implementations of __array_function__ and ufunc overrides\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moverrides\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ARRAY_FUNCTIONS \u001B[38;5;28;01mas\u001B[39;00m _array_functions\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ufunc \u001B[38;5;28;01mas\u001B[39;00m _ufunc\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'ARRAY_FUNCTIONS' from 'numpy.core.overrides' (C:\\Users\\kausikdevanathan\\anaconda3\\envs\\SIH\\Lib\\site-packages\\numpy\\core\\overrides.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer,pipeline,AutoModelForSequenceClassification\n\u001B[0;32m      3\u001B[0m model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcardiffnlp/twitter-roberta-base-sentiment\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      4\u001B[0m sentiment \u001B[38;5;241m=\u001B[39m pipeline(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msentiment-analysis\u001B[39m\u001B[38;5;124m\"\u001B[39m, model\u001B[38;5;241m=\u001B[39mmodel_path, tokenizer\u001B[38;5;241m=\u001B[39mmodel_path)\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1229\u001B[0m, in \u001B[0;36m_handle_fromlist\u001B[1;34m(module, fromlist, import_, recursive)\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1174\u001B[0m, in \u001B[0;36m_LazyModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1172\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_module(name)\n\u001B[0;32m   1173\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m-> 1174\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_module(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module[name])\n\u001B[0;32m   1175\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[0;32m   1176\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1186\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[1;34m(self, module_name)\u001B[0m\n\u001B[0;32m   1184\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m module_name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m   1185\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m-> 1186\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   1187\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to import \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m because of the following error (look up to see its\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1188\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m traceback):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1189\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\ncannot import name 'ARRAY_FUNCTIONS' from 'numpy.core.overrides' (C:\\Users\\kausikdevanathan\\anaconda3\\envs\\SIH\\Lib\\site-packages\\numpy\\core\\overrides.py)"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer,pipeline,AutoModelForSequenceClassification\n",
    "model_path = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "sentiment = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T07:37:06.690664800Z",
     "start_time": "2023-09-18T07:36:55.114799400Z"
    }
   },
   "id": "b0fe4ddc112710fe"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'LABEL_2', 'score': 0.9876530170440674}]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"I am very happy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:26:48.049486500Z",
     "start_time": "2023-09-18T05:26:47.742354500Z"
    }
   },
   "id": "36cc7a8288f377e2"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'LABEL_0', 'score': 0.949698805809021}]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"I am very sad\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:26:48.209656900Z",
     "start_time": "2023-09-18T05:26:48.049486500Z"
    }
   },
   "id": "bc32b3a6b06604f0"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'LABEL_0', 'score': 0.9702324867248535}]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"I am very angry\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:26:48.209656900Z",
     "start_time": "2023-09-18T05:26:48.097355700Z"
    }
   },
   "id": "dd104be9dae1ec4"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm -q\n",
    "# Run this if you don't have spacy installed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:26:48.209656900Z",
     "start_time": "2023-09-18T05:26:48.144210Z"
    }
   },
   "id": "c24f2404543b9aa2"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import text_hammer as th\n",
    "# from tqdm._tqdm_notebook import tqdm_notebook\n",
    "# tqdm_notebook.pandas()\n",
    "# def text_preprocessing(df,col_name):\n",
    "#     column = col_name\n",
    "#     df[column] = df[column].progress_apply(lambda x:str(x).lower())\n",
    "#     #     df[column] = df[column].progress_apply(lambda x: th.cont_exp(x))\n",
    "#     #you're -> you are; i'm -> i am\n",
    "#     df[column] = df[column].progress_apply(lambda x: th.remove_emails(x))\n",
    "#     df[column] = df[column].progress_apply(lambda x: th.remove_html_tags(x))\n",
    "#     df[column] = df[column].progress_apply(lambda x: th.remove_special_chars(x))\n",
    "#     df[column] = df[column].progress_apply(lambda x: th.remove_accented_chars(x))\n",
    "#     df[column] = df[column].progress_apply(lambda x: th.make_base(x)) #ran -> run,\n",
    "#     return(df)\n",
    "# \n",
    "# df['text'] = text_preprocessing(df,'text')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:26:48.209656900Z",
     "start_time": "2023-09-18T05:26:48.145678800Z"
    }
   },
   "id": "7efdfb237c2c1c1a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# import multiprocessing\n",
    "# import time\n",
    "# \n",
    "# def text_preprocessing_worker(text):\n",
    "#     \"\"\"Preprocess text using a specific function.\"\"\"\n",
    "# \n",
    "#     # Preprocess the text using your chosen function\n",
    "#     preprocessed_text = th.cont_exp(text)\n",
    "# \n",
    "#     return preprocessed_text\n",
    "# \n",
    "# # Create a pool of workers to execute the text preprocessing function in parallel\n",
    "# start = time.time()\n",
    "# pool = multiprocessing.Pool(4)\n",
    "# \n",
    "# # Apply the text preprocessing function to each text in the DataFrame using the pool of workers\n",
    "# preprocessed_texts = pool.map(text_preprocessing_worker, df['text'])\n",
    "# \n",
    "# # Add the preprocessed texts to the DataFrame\n",
    "# df['text'] = preprocessed_texts\n",
    "# \n",
    "# # Close the pool of workers\n",
    "# pool.close()\n",
    "# print(time.time() - start)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:26:48.209656900Z",
     "start_time": "2023-09-18T05:26:48.153587Z"
    }
   },
   "id": "fe0adfac35b294b7"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1600000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ee32c6c68c64043bde5529582a67980"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1600000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c5dc0a667084bb8b392eba5944c4761"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1600000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a572b03ee9004cd68f82d050353dfb73"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1600000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2c6a62564204f6aaaceb7dadd7aca0a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1600000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9df591be737b4bff96afcc8abc525c8a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1600000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6517553ebd0a4c1ea004e0b748a8cdff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kausikdevanathan\\anaconda3\\envs\\SIH\\Lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 1340, in time\n",
      "    exec(code, glob, local_ns)\n",
      "  File \"<timed exec>\", line 36, in <module>\n",
      "  File \"C:\\Users\\kausikdevanathan\\anaconda3\\envs\\SIH\\Lib\\site-packages\\pandas\\core\\frame.py\", line 4084, in __setitem__\n",
      "    self._set_item_frame_value(key, value)\n",
      "  File \"C:\\Users\\kausikdevanathan\\anaconda3\\envs\\SIH\\Lib\\site-packages\\pandas\\core\\frame.py\", line 4212, in _set_item_frame_value\n",
      "    raise ValueError(\"Columns must be same length as key\")\n",
      "ValueError: Columns must be same length as key\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kausikdevanathan\\anaconda3\\envs\\SIH\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kausikdevanathan\\anaconda3\\envs\\SIH\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kausikdevanathan\\anaconda3\\envs\\SIH\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kausikdevanathan\\anaconda3\\envs\\SIH\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kausikdevanathan\\anaconda3\\envs\\SIH\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kausikdevanathan\\anaconda3\\envs\\SIH\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1155, in get_records\n",
      "    FrameInfo(\n",
      "  File \"C:\\Users\\kausikdevanathan\\anaconda3\\envs\\SIH\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 780, in __init__\n",
      "    ix = inspect.getsourcelines(frame)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kausikdevanathan\\anaconda3\\envs\\SIH\\Lib\\inspect.py\", line 1244, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "                  ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kausikdevanathan\\anaconda3\\envs\\SIH\\Lib\\inspect.py\", line 1081, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import unicodedata\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "\n",
    "def vectorized_text_preprocessing_tqdm(df, col_name):\n",
    "    \"\"\"\n",
    "    Performs text preprocessing on a Pandas DataFrame column using vectorized operations and shows the progress bar.\n",
    "\n",
    "    Args:\n",
    "        df: A Pandas DataFrame.\n",
    "        col_name: The name of the column to preprocess.\n",
    "\n",
    "    Returns:\n",
    "        A Pandas DataFrame with the preprocessed column.\n",
    "    \"\"\"\n",
    "\n",
    "    # Show the progress bar.\n",
    "    tqdm_notebook.pandas()\n",
    "\n",
    "    # Convert the column to lowercase.\n",
    "    df[col_name] = df[col_name].progress_apply(lambda x: x.lower())\n",
    "\n",
    "    # Remove emails, HTML tags, special characters, and accented characters.\n",
    "    df[col_name] = df[col_name].progress_apply(lambda x: x.replace(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", \"\"))\n",
    "    df[col_name] = df[col_name].progress_apply(lambda x: x.replace(r\"<[^>]*>\", \"\"))\n",
    "    df[col_name] = df[col_name].progress_apply(lambda x: x.replace(r\"[^\\w\\s]\", \"\"))\n",
    "    df[col_name] = df[col_name].progress_apply(lambda x: unicodedata.normalize(\"NFKD\", x).encode(\"ascii\", errors=\"ignore\").decode(\"ascii\"))\n",
    "\n",
    "    # Make the text base form.\n",
    "    df[col_name] = df[col_name].progress_apply(lambda x: \" \".join(x.split()))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Preprocess the text column using the vectorized approach with progress bar.\n",
    "df['text'] = vectorized_text_preprocessing_tqdm(df, \"text\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T07:37:25.227092Z",
     "start_time": "2023-09-18T07:37:09.753988100Z"
    }
   },
   "id": "a12e77177f2db6c4"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:27:04.996953600Z",
     "start_time": "2023-09-18T05:27:04.992605400Z"
    }
   },
   "id": "4e5d8c632755b7ec"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\kausikdevanathan\\DataspellProjects\\sentimentAnalysis\\sentiment140\\preprocessed.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:27:11.768630100Z",
     "start_time": "2023-09-18T05:27:04.999899Z"
    }
   },
   "id": "fdd9561484c9fb51"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "sentiment\n0    800000\n4    800000\nName: count, dtype: int64"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:27:11.821129100Z",
     "start_time": "2023-09-18T05:27:11.768630100Z"
    }
   },
   "id": "efa9e9bd66b802da"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ARRAY_FUNCTIONS' from 'numpy.core.overrides' (C:\\Users\\kausikdevanathan\\anaconda3\\envs\\SIH\\Lib\\site-packages\\numpy\\core\\overrides.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split,KFold,StratifiedKFold\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m accuracy_score,classification_report,confusion_matrix\n\u001B[0;32m      4\u001B[0m X \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\sklearn\\__init__.py:83\u001B[0m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001B[39;00m\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;66;03m# process, as it may not be compiled yet\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     77\u001B[0m     \u001B[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001B[39;00m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001B[39;00m\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     80\u001B[0m         __check_build,  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[0;32m     81\u001B[0m         _distributor_init,  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[0;32m     82\u001B[0m     )\n\u001B[1;32m---> 83\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m clone\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_show_versions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m show_versions\n\u001B[0;32m     86\u001B[0m     __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     87\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcalibration\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     88\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcluster\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    129\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshow_versions\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    130\u001B[0m     ]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\sklearn\\base.py:19\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_config\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config_context, get_config\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexceptions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m InconsistentVersionWarning\n\u001B[1;32m---> 19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _IS_32BIT\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_estimator_html_repr\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m estimator_html_repr\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_metadata_requests\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _MetadataRequester\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\sklearn\\utils\\__init__.py:22\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_bunch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Bunch\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_estimator_html_repr\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m estimator_html_repr\n\u001B[1;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_param_validation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Interval, validate_params\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclass_weight\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compute_class_weight, compute_sample_weight\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdeprecation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m deprecated\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:15\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msparse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m csr_matrix, issparse\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_config\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config_context, get_config\n\u001B[1;32m---> 15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvalidation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _is_arraylike_not_scalar\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mInvalidParameterError\u001B[39;00m(\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m):\n\u001B[0;32m     19\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;124;03m    does not have a valid type or value.\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\sklearn\\utils\\validation.py:28\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_config \u001B[38;5;28;01mas\u001B[39;00m _get_config\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexceptions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001B[1;32m---> 28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_array_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_isfinite\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FiniteStatus, cy_isfinite\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfixes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _object_dtype_isnan\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:9\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mspecial\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mspecial\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_config\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_config\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfixes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parse_version\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_array_api_dispatch\u001B[39m(array_api_dispatch):\n\u001B[0;32m     13\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Check that array_api_compat is installed and NumPy version is compatible.\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03m    array_api_compat follows NEP29, which has a higher minimum NumPy version than\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;124;03m    scikit-learn.\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\sklearn\\utils\\fixes.py:18\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstats\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mthreadpoolctl\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\scipy\\stats\\__init__.py:608\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03m.. _statsrefmanual:\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    603\u001B[0m \n\u001B[0;32m    604\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    606\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_warnings_errors\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001B[0;32m    607\u001B[0m                                DegenerateDataWarning, FitError)\n\u001B[1;32m--> 608\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_stats_py\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m    609\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_variation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m variation\n\u001B[0;32m    610\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistributions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:37\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m array, asarray, ma\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NumpyVersion\n\u001B[1;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtesting\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m suppress_warnings\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mspatial\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistance\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cdist\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mndimage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _measurements\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\numpy\\testing\\__init__.py:14\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_private\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (_assert_valid_refcount, _gen_alignment_data)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_private\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m extbuild\n\u001B[1;32m---> 14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m overrides\n\u001B[0;32m     16\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     17\u001B[0m     _private\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39m__all__ \u001B[38;5;241m+\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTestCase\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moverrides\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     18\u001B[0m )\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytesttester\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PytestTester\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\numpy\\testing\\overrides.py:6\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"Tools for testing implementations of __array_function__ and ufunc overrides\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moverrides\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ARRAY_FUNCTIONS \u001B[38;5;28;01mas\u001B[39;00m _array_functions\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ufunc \u001B[38;5;28;01mas\u001B[39;00m _ufunc\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mumath\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_umath\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'ARRAY_FUNCTIONS' from 'numpy.core.overrides' (C:\\Users\\kausikdevanathan\\anaconda3\\envs\\SIH\\Lib\\site-packages\\numpy\\core\\overrides.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split,KFold,StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "\n",
    "X = df[\"text\"]\n",
    "y = df[\"sentiment\"]\n",
    "\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Split the test-validation set into test and validation sets\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.50, random_state=42)\n",
    "\n",
    "# Save the train, test, and validation sets to disk\n",
    "X_train.to_csv(r\"C:\\Users\\kausikdevanathan\\DataspellProjects\\sentimentAnalysis\\train_val_test_data\\train.csv\", index=False)\n",
    "X_test.to_csv(r\"C:\\Users\\kausikdevanathan\\DataspellProjects\\sentimentAnalysis\\train_val_test_data\\test.csv\", index=False)\n",
    "X_val.to_csv(r\"C:\\Users\\kausikdevanathan\\DataspellProjects\\sentimentAnalysis\\train_val_test_data\\validation.csv\", index=False)\n",
    "y_train.to_csv(r\"C:\\Users\\kausikdevanathan\\DataspellProjects\\sentimentAnalysis\\train_val_test_data\\train_labels.csv\", index=False)\n",
    "y_test.to_csv(r\"C:\\Users\\kausikdevanathan\\DataspellProjects\\sentimentAnalysis\\train_val_test_data\\test_labels.csv\", index=False)\n",
    "y_val.to_csv(r\"C:\\Users\\kausikdevanathan\\DataspellProjects\\sentimentAnalysis\\train_val_test_data\\validation_labels.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T07:38:44.264627700Z",
     "start_time": "2023-09-18T07:38:42.036112700Z"
    }
   },
   "id": "dc1303620ecfc998"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\n",
    "        \"train\": r\"C:\\Users\\kausikdevanathan\\DataspellProjects\\sentimentAnalysis\\train_val_test_data\\train.csv\",\n",
    "        \"test\": r\"C:\\Users\\kausikdevanathan\\DataspellProjects\\sentimentAnalysis\\train_val_test_data\\test.csv\",\n",
    "        \"validation\": r\"C:\\Users\\kausikdevanathan\\DataspellProjects\\sentimentAnalysis\\train_val_test_data\\validation.csv\",\n",
    "    },\n",
    "    column_names=[\"text\", \"label\"],\n",
    "    cache_dir=\"\",\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:28:25.284773400Z",
     "start_time": "2023-09-18T05:28:23.966418600Z"
    }
   },
   "id": "b653bfb2a4891045"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'label'],\n    num_rows: 1120001\n})"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:27:26.539870200Z",
     "start_time": "2023-09-18T05:27:26.525807200Z"
    }
   },
   "id": "5651b260c751d491"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'full_determinism'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m enable_full_determinism(seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# dataset.full_determinism = False\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[0;32m      6\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel_path,\n\u001B[0;32m      7\u001B[0m     args\u001B[38;5;241m=\u001B[39m{\n\u001B[0;32m      8\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_train_epochs\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m3\u001B[39m,\n\u001B[0;32m      9\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlearning_rate\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m5e-5\u001B[39m,\n\u001B[0;32m     10\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mevaluation_strategy\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     11\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mper_device_train_batch_size\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m32\u001B[39m,\n\u001B[0;32m     12\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mper_device_eval_batch_size\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m32\u001B[39m,\n\u001B[0;32m     13\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogging_steps\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m100\u001B[39m,\n\u001B[0;32m     14\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight_decay\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m0.01\u001B[39m,\n\u001B[0;32m     15\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mload_best_model_at_end\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m     16\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetric_for_best_model\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     17\u001B[0m     },\n\u001B[0;32m     18\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39mdataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     19\u001B[0m     eval_dataset\u001B[38;5;241m=\u001B[39mdataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     20\u001B[0m     tokenizer\u001B[38;5;241m=\u001B[39mmodel_path\n\u001B[0;32m     21\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\transformers\\trainer.py:337\u001B[0m, in \u001B[0;36mTrainer.__init__\u001B[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001B[0m\n\u001B[0;32m    335\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs \u001B[38;5;241m=\u001B[39m args\n\u001B[0;32m    336\u001B[0m \u001B[38;5;66;03m# Seed must be set before instantiating the model when using model\u001B[39;00m\n\u001B[1;32m--> 337\u001B[0m enable_full_determinism(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mseed) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mfull_determinism \u001B[38;5;28;01melse\u001B[39;00m set_seed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mseed)\n\u001B[0;32m    338\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhp_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    339\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdeepspeed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'dict' object has no attribute 'full_determinism'"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer,enable_full_determinism\n",
    "enable_full_determinism(seed=42)\n",
    "\n",
    "# dataset.full_determinism = False\n",
    "trainer = Trainer(\n",
    "    model=model_path,\n",
    "    args={\n",
    "        \"num_train_epochs\": 3,\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"evaluation_strategy\": \"epoch\",\n",
    "        \"per_device_train_batch_size\": 32,\n",
    "        \"per_device_eval_batch_size\": 32,\n",
    "        \"logging_steps\": 100,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"metric_for_best_model\": \"accuracy\",\n",
    "    },\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=model_path\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:39:29.600341600Z",
     "start_time": "2023-09-18T05:39:29.499740700Z"
    }
   },
   "id": "dd6942170cd007e8"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The batch received was empty, your model won't be able to train on it. Double-check that your training dataset contains keys expected by the model: input_ids,attention_mask,token_type_ids,position_ids,head_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,label,labels,label_ids.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 36\u001B[0m\n\u001B[0;32m     28\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[0;32m     29\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m     30\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[0;32m     31\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39mdataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     32\u001B[0m     eval_dataset\u001B[38;5;241m=\u001B[39mdataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     33\u001B[0m )\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m---> 36\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# Evaluate the model\u001B[39;00m\n\u001B[0;32m     39\u001B[0m trainer\u001B[38;5;241m.\u001B[39mevaluate()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\transformers\\trainer.py:1553\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inner_training_loop(\n\u001B[0;32m   1554\u001B[0m         args\u001B[38;5;241m=\u001B[39margs,\n\u001B[0;32m   1555\u001B[0m         resume_from_checkpoint\u001B[38;5;241m=\u001B[39mresume_from_checkpoint,\n\u001B[0;32m   1556\u001B[0m         trial\u001B[38;5;241m=\u001B[39mtrial,\n\u001B[0;32m   1557\u001B[0m         ignore_keys_for_eval\u001B[38;5;241m=\u001B[39mignore_keys_for_eval,\n\u001B[0;32m   1558\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\transformers\\trainer.py:1835\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   1832\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_begin(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[0;32m   1834\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39maccumulate(model):\n\u001B[1;32m-> 1835\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_step(model, inputs)\n\u001B[0;32m   1837\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1838\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[0;32m   1839\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_tpu_available()\n\u001B[0;32m   1840\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[0;32m   1841\u001B[0m ):\n\u001B[0;32m   1842\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[0;32m   1843\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\transformers\\trainer.py:2672\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[1;34m(self, model, inputs)\u001B[0m\n\u001B[0;32m   2654\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2655\u001B[0m \u001B[38;5;124;03mPerform a training step on a batch of inputs.\u001B[39;00m\n\u001B[0;32m   2656\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2669\u001B[0m \u001B[38;5;124;03m    `torch.Tensor`: The tensor with training loss on this batch.\u001B[39;00m\n\u001B[0;32m   2670\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2671\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m-> 2672\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_inputs(inputs)\n\u001B[0;32m   2674\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_sagemaker_mp_enabled():\n\u001B[0;32m   2675\u001B[0m     loss_mb \u001B[38;5;241m=\u001B[39m smp_forward_backward(model, inputs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mgradient_accumulation_steps)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\transformers\\trainer.py:2622\u001B[0m, in \u001B[0;36mTrainer._prepare_inputs\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m   2620\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_input(inputs)\n\u001B[0;32m   2621\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(inputs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 2622\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2623\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe batch received was empty, your model won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt be able to train on it. Double-check that your \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2624\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining dataset contains keys expected by the model: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signature_columns)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2625\u001B[0m     )\n\u001B[0;32m   2626\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpast_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_past \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2627\u001B[0m     inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmems\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_past\n",
      "\u001B[1;31mValueError\u001B[0m: The batch received was empty, your model won't be able to train on it. Double-check that your training dataset contains keys expected by the model: input_ids,attention_mask,token_type_ids,position_ids,head_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,label,labels,label_ids."
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer,enable_full_determinism\n",
    "\n",
    "enable_full_determinism(seed=42)\n",
    "\n",
    "model_path = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Set the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Create a trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "trainer.evaluate()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:41:36.515271200Z",
     "start_time": "2023-09-18T05:41:32.878287700Z"
    }
   },
   "id": "43727134d7f3790e"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TextClassificationPipeline' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 19\u001B[0m\n\u001B[0;32m      5\u001B[0m training_args \u001B[38;5;241m=\u001B[39m TrainingArguments(\n\u001B[0;32m      6\u001B[0m     output_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      7\u001B[0m     evaluation_strategy\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     15\u001B[0m     metric_for_best_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     16\u001B[0m )\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Create a trainer\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[0;32m     20\u001B[0m     model\u001B[38;5;241m=\u001B[39msentiment,\n\u001B[0;32m     21\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[0;32m     22\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39mdataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     23\u001B[0m     eval_dataset\u001B[38;5;241m=\u001B[39mdataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     24\u001B[0m )\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m     27\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\transformers\\trainer.py:506\u001B[0m, in \u001B[0;36mTrainer.__init__\u001B[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001B[0m\n\u001B[0;32m    501\u001B[0m \u001B[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001B[39;00m\n\u001B[0;32m    502\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    503\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mplace_model_on_device\n\u001B[0;32m    504\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquantization_method\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m QuantizationMethod\u001B[38;5;241m.\u001B[39mBITS_AND_BYTES\n\u001B[0;32m    505\u001B[0m ):\n\u001B[1;32m--> 506\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_move_model_to_device(model, args\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m    508\u001B[0m \u001B[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001B[39;00m\n\u001B[0;32m    509\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_model_parallel:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\transformers\\trainer.py:730\u001B[0m, in \u001B[0;36mTrainer._move_model_to_device\u001B[1;34m(self, model, device)\u001B[0m\n\u001B[0;32m    729\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_move_model_to_device\u001B[39m(\u001B[38;5;28mself\u001B[39m, model, device):\n\u001B[1;32m--> 730\u001B[0m     model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m    731\u001B[0m     \u001B[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001B[39;00m\n\u001B[0;32m    732\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mparallel_mode \u001B[38;5;241m==\u001B[39m ParallelMode\u001B[38;5;241m.\u001B[39mTPU \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtie_weights\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'TextClassificationPipeline' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, enable_full_determinism\n",
    "enable_full_determinism(seed=42)\n",
    "\n",
    "# Set the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Create a trainer\n",
    "trainer = Trainer(\n",
    "    model=sentiment,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "trainer.evaluate()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:41:52.817768300Z",
     "start_time": "2023-09-18T05:41:52.702986100Z"
    }
   },
   "id": "550c7ed608d2b8f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install accelerate -U "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-18T05:27:28.160883Z"
    }
   },
   "id": "1e5172d50d5217d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-18T05:27:28.165276400Z"
    }
   },
   "id": "727d12c869c2db81"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-18T05:27:28.165276400Z"
    }
   },
   "id": "322ca9bee8baa343"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import datasets\n",
    "# dataset = datasets.load_dataset(\"sentiment140\", split=\"train\")\n",
    "# import datasets\n",
    "\n",
    "# dataset = datasets.load_dataset(\"sentiment140\",encode=\"latin-1\", split=\"train\")\n",
    "dataset = datasets.load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\n",
    "        \"train\": r\"C:\\Users\\kausikdevanathan\\DataspellProjects\\sentimentAnalysis\\train_val_test_data\\train.csv\",\n",
    "        \"test\": r\"C:\\Users\\kausikdevanathan\\DataspellProjects\\sentimentAnalysis\\train_val_test_data\\test.csv\",\n",
    "        \"validation\": r\"C:\\Users\\kausikdevanathan\\DataspellProjects\\sentimentAnalysis\\train_val_test_data\\validation.csv\",\n",
    "    },\n",
    "    column_names=[\"text\", \"label\"],\n",
    "    cache_dir=\"\",\n",
    ")\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\",padding=True, truncation=True, max_length=128)\n",
    "\n",
    "preprocessed_dataset = []\n",
    "for tweet, label in zip(dataset[\"train\"][\"text\"], dataset[\"validation\"][\"label\"]):\n",
    "    input_ids = tokenizer(tweet, return_tensors=\"pt\").input_ids\n",
    "    preprocessed_dataset.append({\"input_ids\": input_ids, \"labels\": label})\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:27:28.171647500Z",
     "start_time": "2023-09-18T05:27:28.165276400Z"
    }
   },
   "id": "65fa35057d8350e5"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: Tesla T4\n",
      "GPU Memory Total [GB]: 1.536e-05\n"
     ]
    }
   ],
   "source": [
    "!pip install GPUtil -q\n",
    "import GPUtil\n",
    "\n",
    "for gpu in GPUtil.getGPUs():\n",
    "    print(\"GPU Name:\", gpu.name)\n",
    "    print(\"GPU Memory Total [GB]:\", gpu.memoryTotal / 1e9)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T16:00:05.541759800Z",
     "start_time": "2023-09-18T16:00:00.162831100Z"
    }
   },
   "id": "55464ba2fc1e7edc"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (2.0.1)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.15.2-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.0.2-cp311-cp311-win_amd64.whl (2.1 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cudatoolkit (from versions: none)\n",
      "ERROR: No matching distribution found for cudatoolkit\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio cudatoolkit"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T16:00:20.934592600Z",
     "start_time": "2023-09-18T16:00:17.263125400Z"
    }
   },
   "id": "a72ba84464859a7e"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[39], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGPU Device Name:\u001B[39m\u001B[38;5;124m\"\u001B[39m, torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mget_device_name(\u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGPU Device Total Memory [GB]:\u001B[39m\u001B[38;5;124m\"\u001B[39m, torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mget_device_properties(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mtotal_memory \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m1e9\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\torch\\cuda\\__init__.py:365\u001B[0m, in \u001B[0;36mget_device_name\u001B[1;34m(device)\u001B[0m\n\u001B[0;32m    353\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_device_name\u001B[39m(device: Optional[_device_t] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[0;32m    354\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Gets the name of a device.\u001B[39;00m\n\u001B[0;32m    355\u001B[0m \n\u001B[0;32m    356\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    363\u001B[0m \u001B[38;5;124;03m        str: the name of the device\u001B[39;00m\n\u001B[0;32m    364\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 365\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m get_device_properties(device)\u001B[38;5;241m.\u001B[39mname\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\torch\\cuda\\__init__.py:395\u001B[0m, in \u001B[0;36mget_device_properties\u001B[1;34m(device)\u001B[0m\n\u001B[0;32m    385\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_device_properties\u001B[39m(device: _device_t) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m _CudaDeviceProperties:\n\u001B[0;32m    386\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Gets the properties of a device.\u001B[39;00m\n\u001B[0;32m    387\u001B[0m \n\u001B[0;32m    388\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    393\u001B[0m \u001B[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001B[39;00m\n\u001B[0;32m    394\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 395\u001B[0m     _lazy_init()  \u001B[38;5;66;03m# will define _get_device_properties\u001B[39;00m\n\u001B[0;32m    396\u001B[0m     device \u001B[38;5;241m=\u001B[39m _get_device_index(device, optional\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    397\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m device \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m device_count():\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\torch\\cuda\\__init__.py:239\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    236\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    237\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 239\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    240\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    241\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    242\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"GPU Device Name:\", torch.cuda.get_device_name(0))\n",
    "print(\"GPU Device Total Memory [GB]:\", torch.cuda.get_device_properties(0).total_memory / 1e9)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:42:19.129480500Z",
     "start_time": "2023-09-18T05:42:19.066984400Z"
    }
   },
   "id": "310141a90534f012"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "model=model,\n",
    "args=training_args,\n",
    "train_dataset=preprocessed_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-18T05:27:28.171647500Z"
    }
   },
   "id": "2ed7aca430fecee0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T05:27:28.171647500Z",
     "start_time": "2023-09-18T05:27:28.171647500Z"
    }
   },
   "id": "61a1c5c45aadca78"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-18T05:27:28.171647500Z"
    }
   },
   "id": "5ceaffea41a9ea4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-18T05:27:28.171647500Z"
    }
   },
   "id": "a1388ac0cebe2745"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
