{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:25:06.484880600Z",
     "start_time": "2023-09-17T13:23:54.254514500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 2)) (1.24.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 3)) (0.12.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 4)) (3.8.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 5)) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: scikit-learn-intelex in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 7)) (2023.2.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 8)) (4.33.2)\n",
      "Collecting text_hammer (from -r requirements.txt (line 9))\n",
      "  Using cached text_hammer-0.1.5-py3-none-any.whl (7.6 kB)\n",
      "Collecting spacy (from -r requirements.txt (line 10))\n",
      "  Obtaining dependency information for spacy from https://files.pythonhosted.org/packages/d6/9e/8afc618cfed4b5dc602b11754d4d9193a268439704defae301bffca7f04c/spacy-3.6.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached spacy-3.6.1-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting tensorflow (from -r requirements.txt (line 11))\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/9e/b8/ed5f794359d05cd0bffb894c6418da87b93016ee17b669d55c45d1bd5d5b/tensorflow-2.13.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached tensorflow-2.13.0-cp311-cp311-win_amd64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: opendatasets in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 12)) (0.1.22)\n",
      "Collecting datasets (from -r requirements.txt (line 13))\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/09/7e/fd4d6441a541dba61d0acb3c1fd5df53214c2e9033854e837a99dd9e0793/datasets-2.14.5-py3-none-any.whl.metadata\n",
      "  Using cached datasets-2.14.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from -r requirements.txt (line 14)) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (3.1.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 6)) (3.2.0)\n",
      "Requirement already satisfied: daal4py==2023.2.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from scikit-learn-intelex->-r requirements.txt (line 7)) (2023.2.1)\n",
      "Requirement already satisfied: daal==2023.2.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from daal4py==2023.2.1->scikit-learn-intelex->-r requirements.txt (line 7)) (2023.2.1)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from daal==2023.2.1->daal4py==2023.2.1->scikit-learn-intelex->-r requirements.txt (line 7)) (2021.10.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (0.17.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (2023.8.8)\n",
      "Requirement already satisfied: requests in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (4.66.1)\n",
      "Requirement already satisfied: beautifulsoup4==4.9.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from text_hammer->-r requirements.txt (line 9)) (4.9.1)\n",
      "Requirement already satisfied: TextBlob in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from text_hammer->-r requirements.txt (line 9)) (0.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from beautifulsoup4==4.9.1->text_hammer->-r requirements.txt (line 9)) (2.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (6.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (68.0.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from spacy->-r requirements.txt (line 10)) (3.3.0)\n",
      "Collecting tensorflow-intel==2.13.0 (from tensorflow->-r requirements.txt (line 11))\n",
      "  Obtaining dependency information for tensorflow-intel==2.13.0 from https://files.pythonhosted.org/packages/2f/2f/3c84f675931ce3bcbc7e23acbba1e5d7f05ce769adab48322de57a9f5928/tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (4.24.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (1.58.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (0.31.0)\n",
      "Requirement already satisfied: kaggle in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from opendatasets->-r requirements.txt (line 12)) (1.5.16)\n",
      "Requirement already satisfied: click in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from opendatasets->-r requirements.txt (line 12)) (8.1.7)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from datasets->-r requirements.txt (line 13)) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from datasets->-r requirements.txt (line 13)) (0.3.7)\n",
      "Requirement already satisfied: xxhash in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from datasets->-r requirements.txt (line 13)) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from datasets->-r requirements.txt (line 13)) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from datasets->-r requirements.txt (line 13)) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from datasets->-r requirements.txt (line 13)) (3.8.5)\n",
      "Requirement already satisfied: sympy in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from torch->-r requirements.txt (line 14)) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from torch->-r requirements.txt (line 14)) (3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 8)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 8)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 8)) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy->-r requirements.txt (line 10)) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy->-r requirements.txt (line 10)) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tqdm>=4.27->transformers->-r requirements.txt (line 8)) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from jinja2->spacy->-r requirements.txt (line 10)) (2.1.1)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from kaggle->opendatasets->-r requirements.txt (line 12)) (8.0.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from kaggle->opendatasets->-r requirements.txt (line 12)) (4.1.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from sympy->torch->-r requirements.txt (line 14)) (1.3.0)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from TextBlob->text_hammer->-r requirements.txt (line 9)) (3.8.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (3.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (2.3.7)\n",
      "Requirement already satisfied: webencodings in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from bleach->kaggle->opendatasets->-r requirements.txt (line 12)) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from python-slugify->kaggle->opendatasets->-r requirements.txt (line 12)) (1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\kausikdevanathan\\anaconda3\\envs\\sih\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->-r requirements.txt (line 11)) (3.2.2)\n",
      "Using cached spacy-3.6.1-cp311-cp311-win_amd64.whl (12.0 MB)\n",
      "Using cached tensorflow-2.13.0-cp311-cp311-win_amd64.whl (1.9 kB)\n",
      "Using cached tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl (276.6 MB)\n",
      "Using cached datasets-2.14.5-py3-none-any.whl (519 kB)\n",
      "Installing collected packages: spacy, datasets, text_hammer, tensorflow-intel, tensorflow\n",
      "Successfully installed datasets-2.14.5 spacy-3.6.1 tensorflow-2.13.0 tensorflow-intel-2.13.0 text_hammer-0.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:Your Kaggle Key:Downloading sentiment140.zip to .\\sentiment140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80.9M/80.9M [00:04<00:00, 20.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/kazanova/sentiment140\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:27:22.775999900Z",
     "start_time": "2023-09-17T13:26:50.740223300Z"
    }
   },
   "id": "24baa191e81bc95e"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "   sentiment          id                          date     query  \\\n0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n\n              user                                               text  \n0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n1    scotthamilton  is upset that he can't update his Facebook by ...  \n2         mattycus  @Kenichan I dived many times for the ball. Man...  \n3          ElleCTF    my whole body feels itchy and like its on fire   \n4           Karoli  @nationwideclass no, it's not behaving at all....  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>id</th>\n      <th>date</th>\n      <th>query</th>\n      <th>user</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\kausikdevanathan\\DataspellProjects\\SIH\\sentimentAnalysis\\sentiment140\\training.1600000.processed.noemoticon.csv\",names=[\"sentiment\",\"id\",\"date\",\"query\",\"user\",\"text\"],encoding='latin-1')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:29.179855Z",
     "start_time": "2023-09-17T13:55:24.366628400Z"
    }
   },
   "id": "932b49979d9817b1"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "sentiment    0\nid           0\ndate         0\nquery        0\nuser         0\ntext         0\ndtype: int64"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:29.444913100Z",
     "start_time": "2023-09-17T13:55:29.179855Z"
    }
   },
   "id": "ffa7ff97050dc84c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df.drop([\"id\",\"date\",\"query\",\"user\"],axis=1,inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:29.539095200Z",
     "start_time": "2023-09-17T13:55:29.444913100Z"
    }
   },
   "id": "6ab08b23077f4974"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   sentiment                                               text\n0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n1          0  is upset that he can't update his Facebook by ...\n2          0  @Kenichan I dived many times for the ball. Man...\n3          0    my whole body feels itchy and like its on fire \n4          0  @nationwideclass no, it's not behaving at all....",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:29.539095200Z",
     "start_time": "2023-09-17T13:55:29.485533200Z"
    }
   },
   "id": "d6f036ab942a77a4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer,pipeline\n",
    "model_path = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "sentiment = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:42.988389400Z",
     "start_time": "2023-09-17T13:55:29.495281500Z"
    }
   },
   "id": "b0fe4ddc112710fe"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'LABEL_2', 'score': 0.9876530170440674}]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"I am very happy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:42.988389400Z",
     "start_time": "2023-09-17T13:55:39.587515600Z"
    }
   },
   "id": "36cc7a8288f377e2"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'LABEL_0', 'score': 0.949698805809021}]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"I am very sad\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:42.988389400Z",
     "start_time": "2023-09-17T13:55:39.635866100Z"
    }
   },
   "id": "bc32b3a6b06604f0"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'LABEL_0', 'score': 0.9702324867248535}]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"I am very angry\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:42.988389400Z",
     "start_time": "2023-09-17T13:55:39.678443900Z"
    }
   },
   "id": "dd104be9dae1ec4"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;2m[+] Download and installation successful\u001B[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm -q"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:55.143432800Z",
     "start_time": "2023-09-17T13:55:39.720809Z"
    }
   },
   "id": "c24f2404543b9aa2"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import text_hammer as th\n",
    "# from tqdm._tqdm_notebook import tqdm_notebook\n",
    "# tqdm_notebook.pandas()\n",
    "# def text_preprocessing(df,col_name):\n",
    "#     column = col_name\n",
    "#     df[column] = df[column].progress_apply(lambda x:str(x).lower())\n",
    "#     #     df[column] = df[column].progress_apply(lambda x: th.cont_exp(x))\n",
    "#     #you're -> you are; i'm -> i am\n",
    "#     df[column] = df[column].progress_apply(lambda x: th.remove_emails(x))\n",
    "#     df[column] = df[column].progress_apply(lambda x: th.remove_html_tags(x))\n",
    "#     df[column] = df[column].progress_apply(lambda x: th.remove_special_chars(x))\n",
    "#     df[column] = df[column].progress_apply(lambda x: th.remove_accented_chars(x))\n",
    "#     df[column] = df[column].progress_apply(lambda x: th.make_base(x)) #ran -> run,\n",
    "#     return(df)\n",
    "# \n",
    "# df['text'] = text_preprocessing(df,'text')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:55.143432800Z",
     "start_time": "2023-09-17T13:55:55.130237400Z"
    }
   },
   "id": "7efdfb237c2c1c1a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# import multiprocessing\n",
    "# import time\n",
    "# \n",
    "# def text_preprocessing_worker(text):\n",
    "#     \"\"\"Preprocess text using a specific function.\"\"\"\n",
    "# \n",
    "#     # Preprocess the text using your chosen function\n",
    "#     preprocessed_text = th.cont_exp(text)\n",
    "# \n",
    "#     return preprocessed_text\n",
    "# \n",
    "# # Create a pool of workers to execute the text preprocessing function in parallel\n",
    "# start = time.time()\n",
    "# pool = multiprocessing.Pool(4)\n",
    "# \n",
    "# # Apply the text preprocessing function to each text in the DataFrame using the pool of workers\n",
    "# preprocessed_texts = pool.map(text_preprocessing_worker, df['text'])\n",
    "# \n",
    "# # Add the preprocessed texts to the DataFrame\n",
    "# df['text'] = preprocessed_texts\n",
    "# \n",
    "# # Close the pool of workers\n",
    "# pool.close()\n",
    "# print(time.time() - start)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:55.143432800Z",
     "start_time": "2023-09-17T13:55:55.130237400Z"
    }
   },
   "id": "fe0adfac35b294b7"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1600000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a6c0126aeac44298f5539917d0336aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1600000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b1341c3988e4c91a9e4bd32fcce6ccd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1600000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f82db46349944365b85c948c0376370c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1600000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "afc263c0f66e4f73ae7393a44106a0a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1600000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9b02d7e359f4730b2d320ffa42ca3cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1600000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39a527f9b1b24e30bfb4136ffe6a9b51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.2 s\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import unicodedata\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "\n",
    "def vectorized_text_preprocessing_tqdm(df, col_name):\n",
    "    \"\"\"\n",
    "    Performs text preprocessing on a Pandas DataFrame column using vectorized operations and shows the progress bar.\n",
    "\n",
    "    Args:\n",
    "        df: A Pandas DataFrame.\n",
    "        col_name: The name of the column to preprocess.\n",
    "\n",
    "    Returns:\n",
    "        A Pandas DataFrame with the preprocessed column.\n",
    "    \"\"\"\n",
    "\n",
    "    # Show the progress bar.\n",
    "    tqdm_notebook.pandas()\n",
    "\n",
    "    # Convert the column to lowercase.\n",
    "    df[col_name] = df[col_name].progress_apply(lambda x: x.lower())\n",
    "\n",
    "    # Remove emails, HTML tags, special characters, and accented characters.\n",
    "    df[col_name] = df[col_name].progress_apply(lambda x: x.replace(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", \"\"))\n",
    "    df[col_name] = df[col_name].progress_apply(lambda x: x.replace(r\"<[^>]*>\", \"\"))\n",
    "    df[col_name] = df[col_name].progress_apply(lambda x: x.replace(r\"[^\\w\\s]\", \"\"))\n",
    "    df[col_name] = df[col_name].progress_apply(lambda x: unicodedata.normalize(\"NFKD\", x).encode(\"ascii\", errors=\"ignore\").decode(\"ascii\"))\n",
    "\n",
    "    # Make the text base form.\n",
    "    df[col_name] = df[col_name].progress_apply(lambda x: \" \".join(x.split()))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Preprocess the text column using the vectorized approach with progress bar.\n",
    "X_train = vectorized_text_preprocessing_tqdm(df, \"text\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:56:10.341492600Z",
     "start_time": "2023-09-17T13:55:55.143432800Z"
    }
   },
   "id": "a12e77177f2db6c4"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.frame.DataFrame"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:56:39.291764100Z",
     "start_time": "2023-09-17T13:56:39.255149500Z"
    }
   },
   "id": "4e5d8c632755b7ec"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "   sentiment                                               text\n0          0  @switchfoot http://twitpic.com/2y1zl - awww, t...\n1          0  is upset that he can't update his facebook by ...\n2          0  @kenichan i dived many times for the ball. man...\n3          0     my whole body feels itchy and like its on fire\n4          0  @nationwideclass no, it's not behaving at all....",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>is upset that he can't update his facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>@kenichan i dived many times for the ball. man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:56:42.744724Z",
     "start_time": "2023-09-17T13:56:42.728621700Z"
    }
   },
   "id": "5e4c4a3567c1ecd8"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "X_train.to_csv(r\"C:\\Users\\kausikdevanathan\\DataspellProjects\\SIH\\sentimentAnalysis\\sentiment140\\preprocessed.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:57:08.788515700Z",
     "start_time": "2023-09-17T13:57:02.007675100Z"
    }
   },
   "id": "fdd9561484c9fb51"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "sentiment\n0    800000\n4    800000\nName: count, dtype: int64"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['sentiment'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:57:09.975893800Z",
     "start_time": "2023-09-17T13:57:09.929035Z"
    }
   },
   "id": "efa9e9bd66b802da"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to find 'C:/Users/kausikdevanathan/DataspellProjects/SIH/sentimentAnalysis\\train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m dataset \u001B[38;5;241m=\u001B[39m datasets\u001B[38;5;241m.\u001B[39mload_dataset(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsv\u001B[39m\u001B[38;5;124m\"\u001B[39m, data_files\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m})\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\datasets\\load.py:2129\u001B[0m, in \u001B[0;36mload_dataset\u001B[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001B[0m\n\u001B[0;32m   2124\u001B[0m verification_mode \u001B[38;5;241m=\u001B[39m VerificationMode(\n\u001B[0;32m   2125\u001B[0m     (verification_mode \u001B[38;5;129;01mor\u001B[39;00m VerificationMode\u001B[38;5;241m.\u001B[39mBASIC_CHECKS) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m save_infos \u001B[38;5;28;01melse\u001B[39;00m VerificationMode\u001B[38;5;241m.\u001B[39mALL_CHECKS\n\u001B[0;32m   2126\u001B[0m )\n\u001B[0;32m   2128\u001B[0m \u001B[38;5;66;03m# Create a dataset builder\u001B[39;00m\n\u001B[1;32m-> 2129\u001B[0m builder_instance \u001B[38;5;241m=\u001B[39m load_dataset_builder(\n\u001B[0;32m   2130\u001B[0m     path\u001B[38;5;241m=\u001B[39mpath,\n\u001B[0;32m   2131\u001B[0m     name\u001B[38;5;241m=\u001B[39mname,\n\u001B[0;32m   2132\u001B[0m     data_dir\u001B[38;5;241m=\u001B[39mdata_dir,\n\u001B[0;32m   2133\u001B[0m     data_files\u001B[38;5;241m=\u001B[39mdata_files,\n\u001B[0;32m   2134\u001B[0m     cache_dir\u001B[38;5;241m=\u001B[39mcache_dir,\n\u001B[0;32m   2135\u001B[0m     features\u001B[38;5;241m=\u001B[39mfeatures,\n\u001B[0;32m   2136\u001B[0m     download_config\u001B[38;5;241m=\u001B[39mdownload_config,\n\u001B[0;32m   2137\u001B[0m     download_mode\u001B[38;5;241m=\u001B[39mdownload_mode,\n\u001B[0;32m   2138\u001B[0m     revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[0;32m   2139\u001B[0m     token\u001B[38;5;241m=\u001B[39mtoken,\n\u001B[0;32m   2140\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39mstorage_options,\n\u001B[0;32m   2141\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig_kwargs,\n\u001B[0;32m   2142\u001B[0m )\n\u001B[0;32m   2144\u001B[0m \u001B[38;5;66;03m# Return iterable dataset in case of streaming\u001B[39;00m\n\u001B[0;32m   2145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m streaming:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\datasets\\load.py:1815\u001B[0m, in \u001B[0;36mload_dataset_builder\u001B[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, **config_kwargs)\u001B[0m\n\u001B[0;32m   1813\u001B[0m     download_config \u001B[38;5;241m=\u001B[39m download_config\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m download_config \u001B[38;5;28;01melse\u001B[39;00m DownloadConfig()\n\u001B[0;32m   1814\u001B[0m     download_config\u001B[38;5;241m.\u001B[39mstorage_options\u001B[38;5;241m.\u001B[39mupdate(storage_options)\n\u001B[1;32m-> 1815\u001B[0m dataset_module \u001B[38;5;241m=\u001B[39m dataset_module_factory(\n\u001B[0;32m   1816\u001B[0m     path,\n\u001B[0;32m   1817\u001B[0m     revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[0;32m   1818\u001B[0m     download_config\u001B[38;5;241m=\u001B[39mdownload_config,\n\u001B[0;32m   1819\u001B[0m     download_mode\u001B[38;5;241m=\u001B[39mdownload_mode,\n\u001B[0;32m   1820\u001B[0m     data_dir\u001B[38;5;241m=\u001B[39mdata_dir,\n\u001B[0;32m   1821\u001B[0m     data_files\u001B[38;5;241m=\u001B[39mdata_files,\n\u001B[0;32m   1822\u001B[0m )\n\u001B[0;32m   1823\u001B[0m \u001B[38;5;66;03m# Get dataset builder class from the processing script\u001B[39;00m\n\u001B[0;32m   1824\u001B[0m builder_kwargs \u001B[38;5;241m=\u001B[39m dataset_module\u001B[38;5;241m.\u001B[39mbuilder_kwargs\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\datasets\\load.py:1430\u001B[0m, in \u001B[0;36mdataset_module_factory\u001B[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001B[0m\n\u001B[0;32m   1407\u001B[0m \u001B[38;5;66;03m# We have several ways to get a dataset builder:\u001B[39;00m\n\u001B[0;32m   1408\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m   1409\u001B[0m \u001B[38;5;66;03m# - if path is the name of a packaged dataset module\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1421\u001B[0m \n\u001B[0;32m   1422\u001B[0m \u001B[38;5;66;03m# Try packaged\u001B[39;00m\n\u001B[0;32m   1423\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m path \u001B[38;5;129;01min\u001B[39;00m _PACKAGED_DATASETS_MODULES:\n\u001B[0;32m   1424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m PackagedDatasetModuleFactory(\n\u001B[0;32m   1425\u001B[0m         path,\n\u001B[0;32m   1426\u001B[0m         data_dir\u001B[38;5;241m=\u001B[39mdata_dir,\n\u001B[0;32m   1427\u001B[0m         data_files\u001B[38;5;241m=\u001B[39mdata_files,\n\u001B[0;32m   1428\u001B[0m         download_config\u001B[38;5;241m=\u001B[39mdownload_config,\n\u001B[0;32m   1429\u001B[0m         download_mode\u001B[38;5;241m=\u001B[39mdownload_mode,\n\u001B[1;32m-> 1430\u001B[0m     )\u001B[38;5;241m.\u001B[39mget_module()\n\u001B[0;32m   1431\u001B[0m \u001B[38;5;66;03m# Try locally\u001B[39;00m\n\u001B[0;32m   1432\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m path\u001B[38;5;241m.\u001B[39mendswith(filename):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\datasets\\load.py:958\u001B[0m, in \u001B[0;36mPackagedDatasetModuleFactory.get_module\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    956\u001B[0m base_path \u001B[38;5;241m=\u001B[39m Path(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_dir \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mexpanduser()\u001B[38;5;241m.\u001B[39mresolve()\u001B[38;5;241m.\u001B[39mas_posix()\n\u001B[0;32m    957\u001B[0m patterns \u001B[38;5;241m=\u001B[39m sanitize_patterns(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_files) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_files \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m get_data_patterns(base_path)\n\u001B[1;32m--> 958\u001B[0m data_files \u001B[38;5;241m=\u001B[39m DataFilesDict\u001B[38;5;241m.\u001B[39mfrom_patterns(\n\u001B[0;32m    959\u001B[0m     patterns,\n\u001B[0;32m    960\u001B[0m     download_config\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdownload_config,\n\u001B[0;32m    961\u001B[0m     base_path\u001B[38;5;241m=\u001B[39mbase_path,\n\u001B[0;32m    962\u001B[0m )\n\u001B[0;32m    963\u001B[0m supports_metadata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname \u001B[38;5;129;01min\u001B[39;00m _MODULE_SUPPORTS_METADATA\n\u001B[0;32m    964\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_files \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m supports_metadata \u001B[38;5;129;01mand\u001B[39;00m patterns \u001B[38;5;241m!=\u001B[39m DEFAULT_PATTERNS_ALL:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\datasets\\data_files.py:674\u001B[0m, in \u001B[0;36mDataFilesDict.from_patterns\u001B[1;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001B[0m\n\u001B[0;32m    671\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m()\n\u001B[0;32m    672\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, patterns_for_key \u001B[38;5;129;01min\u001B[39;00m patterns\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m    673\u001B[0m     out[key] \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 674\u001B[0m         DataFilesList\u001B[38;5;241m.\u001B[39mfrom_patterns(\n\u001B[0;32m    675\u001B[0m             patterns_for_key,\n\u001B[0;32m    676\u001B[0m             base_path\u001B[38;5;241m=\u001B[39mbase_path,\n\u001B[0;32m    677\u001B[0m             allowed_extensions\u001B[38;5;241m=\u001B[39mallowed_extensions,\n\u001B[0;32m    678\u001B[0m             download_config\u001B[38;5;241m=\u001B[39mdownload_config,\n\u001B[0;32m    679\u001B[0m         )\n\u001B[0;32m    680\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(patterns_for_key, DataFilesList)\n\u001B[0;32m    681\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m patterns_for_key\n\u001B[0;32m    682\u001B[0m     )\n\u001B[0;32m    683\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\datasets\\data_files.py:579\u001B[0m, in \u001B[0;36mDataFilesList.from_patterns\u001B[1;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001B[0m\n\u001B[0;32m    576\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m pattern \u001B[38;5;129;01min\u001B[39;00m patterns:\n\u001B[0;32m    577\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    578\u001B[0m         data_files\u001B[38;5;241m.\u001B[39mextend(\n\u001B[1;32m--> 579\u001B[0m             resolve_pattern(\n\u001B[0;32m    580\u001B[0m                 pattern,\n\u001B[0;32m    581\u001B[0m                 base_path\u001B[38;5;241m=\u001B[39mbase_path,\n\u001B[0;32m    582\u001B[0m                 allowed_extensions\u001B[38;5;241m=\u001B[39mallowed_extensions,\n\u001B[0;32m    583\u001B[0m                 download_config\u001B[38;5;241m=\u001B[39mdownload_config,\n\u001B[0;32m    584\u001B[0m             )\n\u001B[0;32m    585\u001B[0m         )\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m:\n\u001B[0;32m    587\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m has_magic(pattern):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SIH\\Lib\\site-packages\\datasets\\data_files.py:368\u001B[0m, in \u001B[0;36mresolve_pattern\u001B[1;34m(pattern, base_path, allowed_extensions, download_config)\u001B[0m\n\u001B[0;32m    366\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m allowed_extensions \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    367\u001B[0m         error_msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m with any supported extension \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(allowed_extensions)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 368\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(error_msg)\n\u001B[0;32m    369\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: Unable to find 'C:/Users/kausikdevanathan/DataspellProjects/SIH/sentimentAnalysis\\train.csv'"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset(\"csv\", data_files={\"train\": \"train.csv\", \"validation\": \"validation.csv\", \"test\": \"test.csv\"}) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:57:46.388730100Z",
     "start_time": "2023-09-17T13:57:42.602811300Z"
    }
   },
   "id": "dc1303620ecfc998"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b653bfb2a4891045"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
